{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import os\n",
    "from data import *\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torch import nn\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reweight_groups = False\n",
    "automatic_adjustment = False\n",
    "use_normalized_loss = False\n",
    "lr = 0.001\n",
    "alpha = 0.2\n",
    "batch_size = 64\n",
    "weight_decay = 0\n",
    "gamma = 0.1\n",
    "n_epochs = 10\n",
    "seed = 0\n",
    "generalization_adjustment = \"0\"\n",
    "log_every = 50\n",
    "model = \"resnet50\"\n",
    "log_dir = \"./logs\"\n",
    "save_best = True\n",
    "save_last = False\n",
    "mode = 'w'\n",
    "robust = False\n",
    "robust_step_size = 0.01\n",
    "log_every = 50\n",
    "save_step = 10\n",
    "save_best = True\n",
    "save_last = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 4795 | Val data:  1199 | Test data:  1199\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "logger = Logger(os.path.join(log_dir, 'log.txt'), mode=mode)\n",
    "set_seed(seed)\n",
    "\n",
    "train_data, val_data, test_data = get_confounder_splits(\n",
    "    data_dir=\"../datasets/waterbird\", augment_data=False)\n",
    "\n",
    "loader_kwargs = {'batch_size': batch_size, 'pin_memory': False}\n",
    "train_loader = train_data.get_loader(\n",
    "    train=True, reweight_groups=reweight_groups, **loader_kwargs)\n",
    "val_loader = val_data.get_loader(\n",
    "    train=False, reweight_groups=False, ** loader_kwargs)\n",
    "test_loader = test_data.get_loader(\n",
    "    train=False, reweight_groups=False, **loader_kwargs)\n",
    "\n",
    "print(\n",
    "    f'Train data: {train_data.__len__()} | Val data:  {val_data.__len__()} | Test data:  {test_data.__len__()}')\n",
    "\n",
    "data = {}\n",
    "data['train_loader'] = train_loader\n",
    "data['val_loader'] = val_loader\n",
    "data['test_loader'] = test_loader\n",
    "data['train_data'] = train_data\n",
    "data['val_data'] = val_data\n",
    "data['test_data'] = test_data\n",
    "n_classes = train_data.n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2, progress=True)\n",
    "model.fc = nn.Linear(in_features=model.fc.in_features, out_features=2)\n",
    "\n",
    "logger.flush()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "train_csv_logger = CSVBatchLogger(os.path.join(\n",
    "    log_dir, 'train.csv'), train_data.n_groups, mode=mode)\n",
    "val_csv_logger = CSVBatchLogger(os.path.join(\n",
    "    log_dir, 'val.csv'), train_data.n_groups, mode=mode)\n",
    "test_csv_logger = CSVBatchLogger(os.path.join(\n",
    "    log_dir, 'test.csv'), train_data.n_groups, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [0]:\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/75 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    dataset=data,\n",
    "    logger=logger,\n",
    "    train_csv_logger=train_csv_logger,\n",
    "    val_csv_logger=val_csv_logger,\n",
    "    test_csv_logger=test_csv_logger,\n",
    "    alpha=alpha,\n",
    "    gamma=gamma,\n",
    "    robust=robust,\n",
    "    robust_step_size=robust_step_size,\n",
    "    use_normalized_loss=use_normalized_loss,\n",
    "    generalization_adjustment=generalization_adjustment,\n",
    "    lr=lr,\n",
    "    weight_decay=weight_decay,\n",
    "    n_epochs=n_epochs,\n",
    "    log_every=log_every,\n",
    "    save_step=save_step,\n",
    "    save_last=save_last,\n",
    "    save_best=save_best,\n",
    "    log_dir=log_dir,\n",
    "    reweight_groups=reweight_groups,\n",
    "    automatic_adjustment=automatic_adjustment)\n",
    "\n",
    "train_csv_logger.close()\n",
    "val_csv_logger.close()\n",
    "test_csv_logger.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
